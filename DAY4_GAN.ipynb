{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cisirtraining/summerschool/blob/master/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4Fa5Eq9dXJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://drive.grand-challenge.org/]\n",
        "!git clone https://github.com/xitonchong/retina_data\n",
        " \n",
        "'''DESIGN DOC:\n",
        "--------------------------------\n",
        "OBJECTIVE:  to demonstrate the capabilities of GAN of synthesizing medical images \n",
        "            through unconditional, semi-supervised manner.  (image synthesis)\n",
        "DL LANGUAGE:  tensorflow 2.0, based on keras\n",
        "            advantage over tensorflow version 1.x:  prebuild computation graph before execution\n",
        "OTHER GAN TASK:  \n",
        "            1.  image segmentation, where given retina image, identify location where lesion is present (if any)\n",
        "            2.  computer vision task:  style transfer, super-resolution (DLSS), interpolate possible frame in between two successive video frame\n",
        "GAN is a heuristic learning method where the cost function does not guarantee convergence, \n",
        "  As space get larger, GAN might have difficulties in guessing the fake image as generator is conjectured to have harder task of\n",
        "  synthesizing image that is close to real image without looking at the input image, discriminator has \"easier\" task as it takes a look\n",
        "  at both input and fake images.  All generator sees are scalar feedback from discriminator (*and its gradient)\n",
        "  it is important to check gradient from output is properly backpropagated into front layers if GAN fails.  \n",
        "  \n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UFTdyB0OL7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir -p images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTl_IzyYNUVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''from google.colab import files\n",
        "files.upload()'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJmL5Jq5OtqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''from google.colab import files\n",
        "files.upload()'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bMS80l-JH0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkseMCcBfxzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install matplotlib\n",
        "!pip install tensorflow==2.0.0beta\n",
        "!pip install pillow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKjg1DF4mU8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Activation, BatchNormalization\n",
        "from tensorflow.keras.layers import Reshape, Input, Dropout\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "import argparse\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYwpYTWse_vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def named_logs(model, logs):\n",
        "    result = {}\n",
        "    for l in zip(model.metrics_names, logs):\n",
        "        result[l[0]] = l[1]\n",
        "    return result\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "#data_dir = '/tf/data'\n",
        "data_dir = './retina_data'\n",
        "data = os.path.join(data_dir, \"*/images/*.jpg\")\n",
        "data_list = glob.glob(data)\n",
        "print(type(data_list[0]))\n",
        "\n",
        "#print(len(data_list))\n",
        "assert len(data_list) == 40\n",
        "random.shuffle(data_list)\n",
        "\n",
        "# function ------------------------------------------\n",
        "\n",
        "def preprocess_image(image):\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.resize(image, [64, 64])\n",
        "  image /= 255.0  # normalize to [0,1] range\n",
        "\n",
        "  return image\n",
        "\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    image = tf.io.read_file(path)\n",
        "    return preprocess_image(image)\n",
        "\n",
        "\n",
        "def change_range(image):\n",
        "    # convert from [0,1] to [-1,1]\n",
        "    return 2*image-1\n",
        "\n",
        "#=================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSpEinZgePdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir='./logs',\n",
        "    histogram_freq=0,\n",
        "    batch_size=10,\n",
        "    write_graph=True,\n",
        "    write_grads=True\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnN5kCLre4MU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pass each data path to dataset object\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(data_list)\n",
        "#print('shape: ', repr(path_ds.output_shapes))\n",
        "#print('type: ', path_ds.output_types)\n",
        "print(path_ds)\n",
        "\n",
        "ds = path_ds.map(load_and_preprocess_image)\n",
        "BATCH_SIZE=10\n",
        "ds  = ds.repeat()\n",
        "ds  = ds.batch(BATCH_SIZE)\n",
        "# buffer size refers to preload how many data into memory as a balance of speed and memory\n",
        "# important for shuffling different batches into network\n",
        "ds  = ds.prefetch(buffer_size=AUTOTUNE) \n",
        "keras_ds = ds.map(change_range)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmH8bTKsJjPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## testing the dataset object output\n",
        "# having a sanity check on pixel min and max\n",
        "for i in range(10):\n",
        "    image = next(iter(keras_ds))\n",
        "    print(i, image.shape)\n",
        "    assert np.min(image) >= -1.0\n",
        "    assert np.max(image) <= 1.0\n",
        "    #print(np.min(image), np.max(image))\n",
        "    # convert image to [0 .. 1] range as plt.savefig expects the value\n",
        "    image = image*0.5 + 0.5\n",
        "    plt.imshow(image[i,:,:,:])\n",
        "    plt.axis('off')\n",
        "    plt.savefig(\"./processed_%d.png\" % i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4ruT--aJpX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real = ['./processed_2.png', './processed_4.png', './processed_8.png']\n",
        "# viewing down-resolutioned input images\n",
        "for imageName in real:\n",
        "    print(imageName)\n",
        "    display(Image(filename=imageName))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsYwegLcN_I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(Image('./dcgan.png'))\n",
        "# the dimension of this example is differnt than picture below. Serves as reference only.  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38jDBsemO7--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GAN TRAINING FLOW\n",
        "display(Image('./gan_training.jpg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y-ptnxqLE0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# warpper to conventional function\n",
        "def conv2d(filters, kernel_size, strides, padding):\n",
        "    return Conv2D(filters=filters, kernel_size=kernel_size, \n",
        "                    strides=strides, padding=padding, \n",
        "                    kernel_initializer='he_normal')\n",
        "\n",
        "def conv2dTranspose(filters, kernel_size, strides, padding):\n",
        "    return Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                    strides=strides, padding=padding, \n",
        "                    kernel_initializer='he_normal')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HERbFpqgN9rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGAN():\n",
        "    def __init__(self):\n",
        "        self.height = 64\n",
        "        self.width  = 64\n",
        "        self.channel= 3\n",
        "        self.img_shape=(self.width, self.height, self.channel)\n",
        "        self.latent_dim = 100\n",
        "        layer_init = 'he_normal'  #kaiming he initializer\n",
        "\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "        #optimizer = SGD(lr=0.00005)\n",
        "        # build models\n",
        "        self.dis = self._build_discriminator()\n",
        "        # compile discriminator,  freeze discriminator pipe g to d, \n",
        "        self.dis.compile(loss='binary_crossentropy', \n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "        # build generator\n",
        "        self.gen = self._build_generator()\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        img = self.gen(z)\n",
        "        # set discriminator before compiling combined network ensures that\n",
        "        # no gradient is flowing through discriminator\n",
        "        self.dis.trainable = False\n",
        "        valid = self.dis(img)\n",
        "\n",
        "        # combined model\n",
        "        self.combined = Model(z, valid)\n",
        "        self.combined.compile(loss='binary_crossentropy', \n",
        "                    optimizer=optimizer)\n",
        "        \n",
        "        # tensorboard attach model\n",
        "        tensorboard.set_model(self.dis)\n",
        "        #tensorboard.set_model(self.combined)\n",
        "\n",
        "    def _build_discriminator(self, padding='same'):\n",
        "        \n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(Conv2D(64, (3,3), strides=(2,2),\n",
        "                input_shape=(self.height, self.width, self.channel),\n",
        "                kernel_initializer='he_normal'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(32, (3,3), strides=(2,2), padding=padding,\n",
        "            kernel_initializer='he_normal'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(16, (3,3), strides=(2,2), padding=padding,\n",
        "            kernel_initializer='he_normal'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1))\n",
        "        model.add(Activation('sigmoid'))\n",
        "        \n",
        "        model.summary()\n",
        "        x = Input(shape=self.img_shape)\n",
        "        prob = model(x)\n",
        "        return Model(x, prob)\n",
        "\n",
        "\n",
        "    def _build_generator(self, padding='same'):\n",
        "\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(Dense(16*16*64, input_shape=(self.latent_dim,)))\n",
        "        #model.add(Activation('relu'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Reshape((16, 16, 64),  input_shape=(16*16*64,)))\n",
        "        model.add(Conv2DTranspose(64, kernel_size=(3,3), strides=(2,2),\n",
        "                padding=padding, kernel_initializer='he_normal'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Conv2DTranspose(64, kernel_size=(3,3), strides=(1,1),\n",
        "                padding=padding, kernel_initializer='he_normal'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Conv2DTranspose(32, \n",
        "                kernel_size=(3,3), strides=(2,2),\n",
        "                padding=padding, kernel_initializer='he_normal'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Conv2DTranspose(self.channel,\n",
        "                kernel_size=(3,3), strides=(1,1),\n",
        "                padding=padding, kernel_initializer='he_normal'))\n",
        "        model.add(Activation('tanh'))\n",
        "            \n",
        "        model.summary()\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img   = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "               \n",
        "    def train(self, epochs=1000, batch_size=32, save_interval=100):\n",
        "        \n",
        "        # adversarial ground trutg\n",
        "        valid = np.ones((batch_size,1))\n",
        "        fake = np.zeros((batch_size,1))\n",
        "        \n",
        "        for epoch in range(epochs+1):\n",
        "\n",
        "            imgs = next(iter(keras_ds))\n",
        "            #--------------------------\n",
        "            # train discriminator\n",
        "            #----------------------------\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            gen_imgs = self.gen.predict(noise)\n",
        "\n",
        "            d_loss_real = self.dis.train_on_batch(imgs, valid)\n",
        "            d_loss_fake = self.dis.train_on_batch(gen_imgs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            #----------------------------\n",
        "            #  train generator\n",
        "            #-----------------------------\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "            print(\"%4d [D loss: %4.3f, acc.: %.2f%%] [g loss: %4.3f]\" %\n",
        "                    (epoch, d_loss[0], d_loss[1]*100, g_loss))\n",
        "            # tensorboard save\n",
        "            tensorboard.on_epoch_end(epoch, named_logs(self.dis, d_loss))\n",
        "            #tensorboard.on_epoch_end(epoch, named_logs(self.combined, g_loss))            \n",
        "            if epoch % save_interval == 0:\n",
        "                print(\"== saving images, \", epoch)\n",
        "                self.save_imgs(epoch)\n",
        "\n",
        "\n",
        "    def save_imgs(self, epoch):\n",
        "        r, c = 5,5\n",
        "        noise = np.random.normal(0, 1, (r*c, self.latent_dim))\n",
        "        gen_imgs=  self.gen.predict(noise)\n",
        "\n",
        "        # rescale images 0-1\n",
        "        gen_imgs = 0.5*gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r,c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt,:,:,:])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"./images/mnist_%d.png\" % epoch)\n",
        "        plt.close()\n",
        "\n",
        "gan = DCGAN()\n",
        "gan.train(batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLGKT7VBOD_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fake = ['./images/mnist_0.png', './images/mnist_600.png', './images/mnist_1000.png']\n",
        "\n",
        "# viewing fake images produces by GAN\n",
        "for imageName in fake:\n",
        "    print(imageName)\n",
        "    display(Image(filename=imageName))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZZnN2lwDLlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# viewing down-resolutioned input images\n",
        "for imageName in real:\n",
        "    print(imageName)\n",
        "    display(Image(filename=imageName))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdRE3ahxFj7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TAKEAWAY:\n",
        "'''\n",
        "1.  processing input into tfRecords or tf dataset format\n",
        "2.  GAN workflow and validate output\n",
        "3.  Tensorboard directory is located in logs. Run tensorboard --logdir=./logs to see. \n",
        "\n",
        "HOMEWORK:\n",
        "1.  checkpoint when training and reloading\n",
        "2.  explore other type, task of GAN\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
